options:
  logging: CLOUD_LOGGING_ONLY
steps:
  - name: "python:3.9-slim"
    id: "ValidateDataset"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install pytest pandas --break-system-packages
        if [ -f "test_wine_dataset.py" ]; then
          echo "Running dataset validation tests..."
          pytest test_wine_dataset.py -v -p no:warnings --tb=short -x
          if [ $? -ne 0 ]; then
            echo "ERROR: Dataset validation failed!"
            exit 1
          fi
        else
          echo "No validation tests found, skipping..."
        fi
        if [ ! -f "wine.csv" ]; then
          echo "ERROR: wine.csv not found!"
          exit 1
        fi
        echo "Dataset validation passed"
  - name: "python:3.9-slim"
    id: "CompilePipeline"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install google-cloud-aiplatform kfp --break-system-packages
        python3 pipeline.py
    waitFor: ["ValidateDataset"]
  - name: "python:3.9-slim"
    id: "RunTrainingPipeline"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install 'google-cloud-aiplatform[pipelines]' google-cloud-storage --break-system-packages
        python3 -c "
        from google.cloud import aiplatform
        from google.cloud import storage
        
        aiplatform.init(project='${PROJECT_ID}', location='europe-west4')
        
        github_url = 'https://raw.githubusercontent.com/DE2025G13/DE2025G13A1/${COMMIT_SHA}/wine.csv'
        
        job = aiplatform.PipelineJob(
            display_name='dataset-triggered-run-${SHORT_SHA}',
            template_path='wine_quality_pipeline_git_triggered.yaml',
            pipeline_root='gs://yannick-pipeline-root',
            enable_caching=False,
            parameter_values={
                'input_data_gcs_path': github_url
            }
        )
        
        job.submit(service_account='793868790421-compute@developer.gserviceaccount.com')
        print(f'Pipeline submitted: {job.resource_name}')
        print(f'Using dataset from commit: ${COMMIT_SHA}')
        "
    waitFor: ["CompilePipeline"]
  - name: "python:3.9-slim"
    id: "RecordSuccessfulCommit"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install packaging google-cloud-storage --break-system-packages
        python3 -c "
        from google.cloud import storage
        
        client = storage.Client()
        bucket = client.bucket('yannick-pipeline-root')
        blob = bucket.blob('datasets/last-successful-dataset-commit.txt')
        blob.upload_from_string('${COMMIT_SHA}')
        print('Recorded successful commit SHA: ${COMMIT_SHA}')
        "
    waitFor: ["RunTrainingPipeline"]